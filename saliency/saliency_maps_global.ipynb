{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04490376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from saliency_utils import *\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "parent_dir = Path.cwd().parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "from model_finetuning.ModelClassAC_CMR import *\n",
    "\n",
    "import torch\n",
    "import neurokit2 as nk\n",
    "from fairseq_signals.models.wav2vec2.wav2vec2_cmsc import Wav2Vec2CMSCModel\n",
    "from omegaconf import OmegaConf\n",
    "from scipy.io import loadmat\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f71265",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_foundational_model = \"/mnt/cat/jdeseo/ECG_FM/ckpts/mimic_iv_ecg_physionet_pretrained.pt\" #path where the ECG-FM mimic_iv_ecg_physionet_pretrained.pt model is saved.\n",
    "path_to_finetuned_weights = \"/mnt/cat/jdeseo/ECG_FM/MyModels/finetuned_model_weights_LA_LV_ratio.pt\" #path where the finetuned model weights are saved\n",
    "path_to_ecgs = \"/mnt/cat/jdeseo/ECG_FM/ECG_processed/segmented/\" #path to the ecgs to be evaluated\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6bb070",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_encoder = torch.load(path_to_foundational_model, weights_only = False)\n",
    "cfg_encoder = ckpt_encoder['cfg']\n",
    "cfg_encoder = OmegaConf.create(cfg_encoder[\"model\"])\n",
    "cfg_encoder[\"saliency\"] = False\n",
    "print(cfg_encoder)\n",
    "encoder = Wav2Vec2CMSCModel(cfg_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f15e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(path_to_finetuned_weights)\n",
    "finetuned_model = ECGRegressionModel(encoder, feature_dim=768, num_outputs=4)\n",
    "finetuned_model.load_state_dict(state_dict)\n",
    "finetuned_model.to(device)\n",
    "finetuned_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_dirs = os.listdir(path_to_ecgs)\n",
    "batch_size = 64\n",
    "batch_num = int(len(ecg_dirs)/batch_size) + 1\n",
    "batch_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157aa7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_maps = []\n",
    "all_ecgs = []\n",
    "for batch in range(batch_num):  \n",
    "    try:\n",
    "        ecg_dirs_batch = ecg_dirs[batch*batch_size:(batch+1)*batch_size]\n",
    "    except:\n",
    "        ecg_dirs = ecg_dirs[batch*batch_size:]\n",
    "    test_samples = [] \n",
    "    for i, ecg_file in enumerate(ecg_dirs):\n",
    "        ecg_samples = []\n",
    "        ecg_dir = path_to_ecgs + ecg_file\n",
    "        ecg = loadmat(ecg_dir)[\"feats\"]\n",
    "        ecg_tensor = torch.from_numpy(ecg).float()\n",
    "        test_samples.append(ecg_tensor) \n",
    "\n",
    "    X_test = torch.stack(test_samples, dim=0) \n",
    "    saliency_maps = compute_vanilla_gradient_saliency(finetuned_model, X_test, target_output_idx=1) #Target outputs: 0: LA max, 1: LA min, 2: LAEF, 3:LALV \n",
    "    all_maps.append(saliency_maps)\n",
    "    all_ecgs.append(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3065566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_maps = torch.cat(all_maps)\n",
    "saliency_collapsed = torch.mean(saliency_maps, dim=1)\n",
    "all_ecgs = torch.cat(all_ecgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969af425",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = \"id_to_visualize (int)\"\n",
    "visualize_ecg_saliency(all_ecgs, saliency_maps, sample_idx=sample_id, smooth = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d928c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"ID\" : [], \"P_wave\" : [], \"PQ\" : [], \"QRS\" : [], \"ST\" : [], \"T_wave\": [], \"TP\": [], \"num_heartbeats\": [], \"Total_saliency\" : []}\n",
    "\n",
    "for i, ecg_file in enumerate(ecg_dirs):\n",
    "    ecg_dir = path_to_ecgs + ecg_file\n",
    "    ecg = loadmat(ecg_dir)[\"feats\"]\n",
    "    try:\n",
    "        _, info = nk.ecg_process(ecg[1,:], sampling_rate=500, method=\"neurokit\")\n",
    "        P_on = info[\"ECG_P_Onsets\"]\n",
    "        P_off = info[\"ECG_P_Offsets\"]\n",
    "        Q = info[\"ECG_Q_Peaks\"]\n",
    "        S = info[\"ECG_S_Peaks\"]\n",
    "        T_on = info[\"ECG_T_Onsets\"]\n",
    "        T_off = info[\"ECG_T_Offsets\"]   \n",
    "        saliency = saliency_collapsed[i,:].cpu()\n",
    "        print(saliency.shape)\n",
    "        avg_sal, num_cycles = average_saliency_per_segment(P_on, P_off, Q, S, T_on, T_off, saliency)\n",
    "\n",
    "        for key in data.keys():\n",
    "            if key == \"ID\":\n",
    "                data[\"ID\"].append(ecg_file)\n",
    "            elif key == \"num_heartbeats\":\n",
    "                data[key].append(num_cycles)\n",
    "            else:\n",
    "                data[key].append(avg_sal[key])\n",
    "    except:\n",
    "        for key in data.keys():\n",
    "            if key == \"ID\":\n",
    "                data[\"ID\"].append(ecg_file)\n",
    "            elif key == \"num_heartbeats\":\n",
    "                data[key].append(0)\n",
    "            else:\n",
    "                data[key].append(None)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac_ecg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
